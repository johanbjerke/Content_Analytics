[Generate MITRE matrix list]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
action.nbtstat.param.verbose = 0
action.notable.param.verbose = 0
action.nslookup.param.verbose = 0
action.ping.param.verbose = 0
action.risk.param.verbose = 0
action.threat_add.param.verbose = 0
alert.track = 0
description = This search formats the MITRE Attack framework table into a list format.
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = DataSourceOverview
request.ui_dispatch_view = search
search = | inputlookup mitre_matrix.csv\
| table "Initial Access" "Execution" "Persistence" "Privilege Escalation" "Defense Evasion" "Credential Access" "Discovery" "Lateral Movement" "Collection" "Exfiltration" "Command And Control"\
| transpose 100 column_name="Tactic"\
| rename "row *" AS technique_*\
| untable Tactic Technique_Order Technique\
| eval Technique_Order=substr(Technique_Order,11,2)\
| sort Technique_Order\
| streamstats count AS Tactic_Order\
| eval Tactic_Order=if(Technique_Order="1",Tactic_Order,null)\
| sort Tactic Tactic_Order\
| filldown Tactic_Order\
| sort Tactic_Order Technique_Order\
| table Tactic Tactic_Order Technique Technique_Order\
| outputlookup mitre_matrix_list.csv

[Generate Datamodel Event Summary - Scheduled]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
action.nbtstat.param.verbose = 0
action.notable.param.verbose = 0
action.nslookup.param.verbose = 0
action.ping.param.verbose = 0
action.risk.param.verbose = 0
action.threat_add.param.verbose = 0
alert.track = 0
cron_schedule = 35 2 * * *
description = This search generates the lookup that contains a count of events indexed per sourcetype.  It is run every 24 hours.
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = DataSourceOverview
request.ui_dispatch_view = search
search = | rest /services/data/models splunk_server=local count=0 \
| table title acceleration.cron_schedule eai:digest \
| rename title as datamodel \
| rename acceleration.cron_schedule AS cron \
| join type=outer datamodel \
    [| rest /services/admin/summarization by_tstats=t splunk_server=local count=0 \
    | eval datamodel=replace('summary.id',"DM_".'eai:acl.app'."_","") \
        ] \
| sort datamodel \
| rename summary.complete AS Acceleration\
| lookup Datamodel_Event_Summary.csv datamodel OUTPUT _time \
| map maxsearches=100 search=" \
| tstats summariesonly=t count AS EventCount,dc(host) AS Hosts from datamodel=$datamodel$ WHERE earliest=\"-24h\" \
| eval datamodel=\"$datamodel$\",Acceleration=\"$Acceleration$\"\
    " \
| eval _time=now()\
| outputlookup createinapp=t Datamodel_Event_Summary.csv

[Sample Sankey Diagram on Documentation Page]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
action.nbtstat.param.verbose = 0
action.notable.param.verbose = 0
action.nslookup.param.verbose = 0
action.ping.param.verbose = 0
action.risk.param.verbose = 0
action.threat_add.param.verbose = 0
alert.track = 0
description = This search generates the lookup used by the Sankey diagram used on the documentation page. This search can be run to update the Sankey to the current environment instead of the bundled sample data.
dispatch.earliest_time = 0
display.general.type = visualizations
display.page.search.tab = visualizations
display.statistics.show = 0
display.visualizations.type = custom
request.ui_dispatch_app = Splunk_Content_Analytics
request.ui_dispatch_view = search
search = | rest splunk_server=local count=0 /services/saved/searches search=action.correlationsearch.enabled \
| rename eai:acl.app as app, title as csearch_name, action.correlationsearch.label as csearch_label, action.notable.param.security_domain as security_domain, action.escu.providing_technologies AS providing_technologies, action.escu.analytic_story AS analytic_story \
| append \
    [ `getsse` ] \
| rex field=qualifiedSearch ".*datamodel(=\"|:\"|\(\"|\s|:|=)(\"|)(?<datamodel>[a-z,A-Z,_]*)" \
| lookup Datamodel_Event_Summary.csv datamodel \
| eval csearch_label=coalesce(csearch_label,csearch_name) \
| fillnull EventCount Hosts \
| fields action.escu.mappings analytic_story csearch_label description qualifiedSearch datamodel EventCount Hosts disabled app displayapp security_domain providing_technologies usecase hasSearch includeSSE datasource displayapp app journey category domain icon description dashboard mitre killchain alertvolume bookmark_status \
| where len(description)>0 \
| spath input="analytic_story" path="{}" output="analytic_story" \
| eval deeplink=case(\
    isnotnull(analytic_story),"DA-ESS-ContentUpdate/analytic_story_details?form.analytic_story_name=".replace(mvindex(analytic_story,0), "\s", "%20"),\
    isnotnull(dashboard),"Splunk_Security_Essentials/".replace(dashboard, "\s", "%20"),\
    1=1,"SplunkEnterpriseSecuritySuite/ess_content_management?textFilter=".replace(csearch_label, "\s", "%20")\
    ) \
| spath input="action.escu.mappings" path=cis20{} output="CIS" \
| spath input="action.escu.mappings" path=mitre_attack{} output="MITRE Attack Technique" \
| spath input="action.escu.mappings" path=kill_chain_phases{} output="Kill Chain Phase" \
| eval "MITRE Attack Technique"=coalesce('MITRE Attack Technique', mitre) \
| lookup kill_chain_phases title AS "Kill Chain Phase" OUTPUT order_title AS kill_chain_phase_order_title \
| eval "Kill Chain Phase Orig"='Kill Chain Phase' \
| eval "Kill Chain Phase"=kill_chain_phase_order_title \
| rename usecase AS "Use Case" \
| lookup use_cases.csv title AS "Use Case" OUTPUT order_title AS use_case_order_title \
| eval "Use Case Orig"=if(isnull('Use Case'),"Other",'Use Case') \
| eval "Use Case"=if(isnull(use_case_order_title), "9_Other",use_case_order_title) \
| rex max_match=0 field="qualifiedSearch" "sourcetype(=\"|=)(?<Sourcetype>[^\s^\"^\)]*)" \
| lookup SourcetypeNormalisation Sourcetype OUTPUT Normalised \
| rex max_match=0 field="qualifiedSearch" "source(=\"|=)(?<Source>[^\s^\"^\)]*)" \
| lookup SourceToSourcetype Source OUTPUT Sourcetype AS SourcetypeFromSource \
| eval Sourcetype=mvdedup(coalesce(Normalised,SourcetypeFromSource,Sourcetype)) \
| eval sourcetype_origin="from_use_case" \
| lookup Installed_sourcetypes.csv Sourcetype OUTPUT sourcetype_origin AS sourcetype_origin2, app AS AddOn \
| lookup Sample_sourcetypes.csv Sourcetype OUTPUT sourcetype_origin AS sourcetype_origin_sample, app AS AddOn_sample \
| eval sourcetype_origin=coalesce(sourcetype_origin2,sourcetype_origin) \
| fields - sourcetype_origin2 \
| eval providing_technologies=split(providing_technologies, ",") \
| rex field=providing_technologies mode=sed "s/[\"\[\]]//g" \
| eval providing_technologies=trim(providing_technologies) \
| rename csearch_label AS "Title", description AS Description, qualifiedSearch as "Detection Search", datamodel AS Datamodel, EventCount AS Events, providing_technologies AS "Providing Technologies" \
| eval Enabled=if(disabled=1, "No", "Yes") \
| eval App=case(app="DA-ESS-ContentUpdate", "ES Content Updates", like(app,"SA-%") OR like(app,"DA-%"), "Enterprise Security", like(Description,"%Security Essentials%"), "Splunk Security Essentials",isnotnull(displayapp),displayapp,1=1, app) \
| join type=outer Datamodel \
    [| rest splunk_server=local count=0 /servicesNS/-/-/admin/datamodel-files \
    | spath input=eai:data output=base_search path=objects{}.baseSearch \
    | spath input=eai:data output=constraints path=objects{}.constraints{}.search \
    | eval tag_content = mvappend(base_search,constraints) \
    | rex max_match=0 field=tag_content "tag=\"?(?<tag_name>\w+)\"?" \
    | mvexpand tag_name \
    | rename title AS datamodel \
    | fields tag_name datamodel \
    | append \
        [| rest splunk_server=local count=0 /servicesNS/-/-/admin/eventtypes \
        | rename eai:acl.app AS app tags AS tag_name \
        | search app="*TA*" \
        | rex max_match=0 field=search "sourcetype=\"?(?<sourcetype>[^\s\"^)]+)\"?" \
        | mvexpand sourcetype \
        | lookup SourcetypeNormalisation Sourcetype AS sourcetype OUTPUT Normalised \
        | eval sourcetype=mvdedup(coalesce(Normalised,sourcetype)) \
        | mvexpand sourcetype \
        | mvexpand tag_name \
        | eval app_sourcetype=mvzip(app,sourcetype,"__") \
        | fields sourcetype tag_name app_sourcetype app \
        | stats values(tag_name) as tag_name by app, sourcetype,app_sourcetype\
            ] \
    | stats first(Hosts) AS Hosts,sum(EventCount) AS "EventCount",first(totalCount) AS totalCount,list(datamodel) as datamodel, list(app) as app, list(app_sourcetype) as app_sourcetype by tag_name \
    | search datamodel=* \
    | eval datamodel=mvdedup(datamodel) \
    | stats first(Hosts) AS Hosts,values(EventCount) AS "EventCount",values(app_sourcetype) as app_sourcetype, values(tag_name) as tags by datamodel \
    | rex max_match=0 field=app_sourcetype "\"?(?<app>.+)__\"?" \
    | rex max_match=0 field=app_sourcetype "__\"?(?<sourcetype>.+)\"?" \
    | eval tags=mvdedup(tags),app=mvdedup(app),EventCount=mvdedup(EventCount) \
    | eventstats sum(EventCount) AS EventCount BY datamodel \
    | fields - app_sourcetype \
    | lookup Datamodel_Event_Summary.csv datamodel \
    | rename datamodel AS Datamodel, tags as Tags, sourcetype AS Sourcetype, app AS AddOn \
    | lookup Installed_sourcetypes.csv Sourcetype OUTPUT sourcetype_origin AS sourcetype_origin \
    | lookup Sample_sourcetypes.csv Sourcetype OUTPUT sourcetype_origin AS sourcetype_origin_sample, app AS AddOn_sample \
    | fillnull Hosts \
    | eval Acceleration=round(Acceleration,2)\
        ] \
| eval Datamodel=coalesce(Datamodel,"-") \
| eval AddOn=coalesce(split(replace(AddOn,"\n","---"),"---"),AddOn,"-"),Sourcetype=coalesce(split(replace(Sourcetype,"\n","---"),"---"),Sourcetype,"-"),sourcetype_origin=coalesce(split(replace(sourcetype_origin,"\n","---"),"---"),sourcetype_origin,"-") \
| lookup Installed_sourcetypes.csv Sourcetype OUTPUT sourcetype_count_24h \
| eval Accelerated=if(Acceleration>0, "Yes","No") \
| eval "Enabled and Accelerated"=if(Acceleration>0 AND Enabled="Yes", "Yes","No") \
| eval "Has Data (DM)"=if(EventCount>0, "Yes", "No") \
| eval "Has Data (Index)"=if('EventCount (Sourcetype)'>0, "Yes", "No") \
| eval Status=case(\
    'Enabled'="Yes" AND ('Has Data (DM)'="Yes" OR 'Has Data (Index)'="Yes"),"Current",\
    ('Has Data (DM)'="Yes" OR 'Has Data (Index)'="Yes"),"Phase 1 - Potential",\
    1=1,"Phase 2 - Needs more data"\
    ) \
| rename EventCount AS "Events (DM)", sourcetype_count_24h AS "Events (Sourcetype)" \
| eval "Detection Type"=if(Datamodel!="-", "Content based on Datamodel", "Content based on Indexed data") \
| eventstats dc(eval(if(Sourcetype="-",null,Sourcetype))) AS "Sourcetypes Installed Count",dc(eval(if(AddOn="-",null,AddOn))) AS "AddOns Installed Count" BY "Title" \
| eval Details="Detection Enabled: ".Enabled \
| eval Details=mvappend(Details, "Detection Type: ".'Detection Type') \
| eval Details=if('Detection Type'="Datamodel",mvappend(Details, "Datamodel accelerated: ".if(coalesce('Acceleration',0)>0,"Yes","No")),Details) \
| eval Details=if('Detection Type'="Datamodel",mvappend(Details, "Datamodel has data (-24h): ".'Has Data (DM)'),Details) \
| eval Details=if('Detection Type'="Datamodel",mvappend(Details, "Hosts with data (-24h): ".'Hosts'),Details) \
| eval Details=if('Detection Type'="Index",mvappend(Details, "Indexed data exists (-24h): ".'Has Data (Index)'),Details) \
| eval Details=mvappend(Details, "Sourcetypes Installed: ".'Sourcetypes Installed Count') \
| eval Details=mvappend(Details, "Add-Ons Installed: ".'AddOns Installed Count') \
| eval Status=case(Status="Current","Enabled and working",Status="Phase 1 - Potential","We have data, content not enabled",Status="Phase 2 - Needs more data","We don’t have data")\
| search Status="*" \
| appendpipe \
    [| stats count AS l1 by App] \
| appendpipe \
    [| stats count AS l2 by App "Detection Type"] \
| appendpipe \
    [| stats count AS l3 by "Detection Type" "Status"] \
| table "Detection Type" App "Status" l1 l2 l3\
| eval LinkSource=case(isnotnull(l1), "All Content", isnotnull(l2), App, isnotnull(l3), 'Detection Type', 1=1,null) \
| eval LinkDestination=case(isnotnull(l1), App, isnotnull(l2), 'Detection Type', isnotnull(l3), 'Status', 1=1,null) \
| eval count=coalesce(l1,l2,l3) \
| where isnotnull(l1) OR isnotnull(l2) OR isnotnull(l3) \
| table LinkSource LinkDestination count\
| outputlookup Sample_Sankey_For_Documentation.csv

[Generate Sourcetype Summary - Scheduled]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
action.nbtstat.param.verbose = 0
action.notable.param.verbose = 0
action.nslookup.param.verbose = 0
action.ping.param.verbose = 0
action.risk.param.verbose = 0
action.threat_add.param.verbose = 0
alert.track = 0
cron_schedule = 0 1 * * *
description = This search generates the lookup the contains all configured sourcetypes in the system. It is run every 24 hours.
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = DataSourceOverview
request.ui_dispatch_view = search
search = | rest splunk_server=local count=0 /servicesNS/-/-/admin/sourcetypes \
| rename eai:acl.app AS app tags AS tag_name \
| table app title \
| sort app title \
| rename title AS Sourcetype \
| join type=outer Sourcetype \
    [| rest splunk_server=local count=0 /servicesNS/-/-/admin/eventtypes \
    | rename eai:acl.app AS app tags AS tag_name \
    | search app="Splunk_TA_windows" \
    | rex max_match=0 field=search "sourcetype=\"?(?<sourcetype>[^\s\"^)]+)\"?" \
    | rex max_match=0 field=search "eventtype=\"?(?<eventtype>[^\s\"^)]+)\"?" \
    | lookup EventtypeToSourcetype Eventtype AS title OUTPUT Sourcetype AS SourcetypeFromEventtype \
    | lookup EventtypeToSourcetype Eventtype AS eventtype OUTPUTNEW Sourcetype AS SourcetypeFromEventtype \
    | eval sourcetype=mvdedup(coalesce(SourcetypeFromEventtype,sourcetype)) \
    | table sourcetype app \
    | mvexpand sourcetype \
    | dedup sourcetype \
    | rename sourcetype AS Sourcetype\
        ] \
| join type=outer Sourcetype \
    [| tstats count,dc(host) AS host_count_24h WHERE index=* earliest=-24h BY sourcetype \
    | rename sourcetype AS Sourcetype, count AS sourcetype_count_24h\
        ] \
| eval sourcetype_count_24h=coalesce(sourcetype_count_24h,0) \
| eval host_count_24h=coalesce(host_count_24h,0) \
| eval sourcetype_origin="installed" \
| table Sourcetype app sourcetype_origin sourcetype_count_24h host_count_24h \
| outputlookup Installed_sourcetypes.csv
